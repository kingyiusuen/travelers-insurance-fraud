{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and Feature Enginerring\n",
    "In this file, we will deal with some of the abnormal data and missing value issues that we discover in the exploratory data analysis. We will also do some transformation on some variables to make them more meaningful. \n",
    "\n",
    "We also considered using some macroeconomic data (such as unemployment rate, the price of S&P 500, etc), as we though that a bad economy might motivate more people to commit fraud, but since the prediction did not improve much, we did not include them in our final model and they won't be discussed further here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw_train.csv')\n",
    "test = pd.read_csv('../data/raw_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    # missing values\n",
    "    df.fillna(-1, inplace=True)\n",
    "    \n",
    "    # ordinal features\n",
    "    df['vehicle_category'] = df['vehicle_category'].map({'Compact': 0, 'Medium': 1, 'Large': 2})\n",
    "    \n",
    "    # binary features\n",
    "    for feature in ['gender', 'living_status']:\n",
    "        unique_values = df[feature].unique()\n",
    "        df[feature] = df[feature].map({unique_values[0]: 0, unique_values[1]: 1})\n",
    "        df.rename(columns={feature: feature + str(unique_values[0])}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first remove the observations whose the target variable is equal to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['fraud'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## age_of_driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Wikipedia, the oldest verified person ever was 122 and the current oldest living person is 115. We are going to treat those whose age is over 100 to as missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.age_of_driver > 100, 'age_of_driver'] = np.nan\n",
    "test.loc[test.age_of_driver > 100, 'age_of_driver'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annual_income\n",
    "There are some -1 values in annual_income. We will set them to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.annual_income == -1, 'annual_income'] = np.nan\n",
    "test.loc[test.annual_income == -1, 'annual_income'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip_code\n",
    "We transformed the zip code data into latitude and longitude using the data from https://www.unitedstateszipcodes.org/zip-code-database/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../data/zip_code_database.csv', newline='') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    zip_to_lat = {}\n",
    "    zip_to_lon = {}\n",
    "    for zip_data in csv_reader:\n",
    "        zip_to_lat[zip_data['zip']] = float(zip_data['latitude'])\n",
    "        zip_to_lon[zip_data['zip']] = float(zip_data['longitude'])\n",
    "        \n",
    "zip_to_lat['0'] = -1\n",
    "zip_to_lon['0'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['latitude'] = df['zip_code'].apply(lambda x: zip_to_lat[str(x)])\n",
    "    df['longitude'] = df['zip_code'].apply(lambda x: zip_to_lon[str(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## claim_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we break the claim dates into year, month, day, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['claim_date'] = pd.to_datetime(df['claim_date'])\n",
    "    df['claim_year'] = df['claim_date'].dt.year\n",
    "    df['claim_month'] = df['claim_date'].dt.month\n",
    "    df['claim_day'] = df['claim_date'].dt.day\n",
    "    df['claim_weekofyear'] = df['claim_date'].dt.weekofyear\n",
    "    df['claim_weekday'] = df['claim_date'].dt.weekday\n",
    "    df['claim_weekend'] = (df['claim_weekday'] >= 5).astype(int)\n",
    "    df['elapsed_time'] = (dt.date(2018, 1, 1) - df['claim_date'].dt.date).dt.days\n",
    "    df.drop(columns=['claim_day_of_week'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating_per_claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a new feature named rating per claim, which is a transformation of two existing features: \n",
    "\n",
    "$$\\text{safty_rating} / (\\text{past_num_of_claims} + 1).$$\n",
    "\n",
    "Our rationale was that the safety rating and the past number of claims are both indicators of a person’s credibility but the credibility indicated by safety rating can be “consumed” by the past number of claims. For a person with a high safety rating, the chance of fraud is still high if he/she has a high number of past claims. The addition of one in the denominator was to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['rating_per_claim'] = df.apply(lambda col: col['safty_rating'] / (col['past_num_of_claims'] + 1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of missing values\n",
    "Now, we will do an imputation for the missing values. For simplicity, we will do a mean/mode imputation for the continuous/categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    # mean imputation for continuous variables\n",
    "    for var in ['age_of_driver', 'annual_income', 'claim_est_payout', 'age_of_vehicle', 'latitude', 'longitude']:\n",
    "        var_mean = df.loc[:, var].mean()\n",
    "        df[var].fillna(var_mean, inplace=True)\n",
    "        \n",
    "    # mode imputation for categorical variables\n",
    "    for var in ['marital_status', 'witness_present_ind']:\n",
    "        var_mode = df.loc[:, var].mode()\n",
    "        df[var].fillna(var_mode, inplace=True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/train_clean.csv', header=True)\n",
    "test.to_csv('../data/test_clean.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
