{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "In this notebook, I used a 5-fold cross-validation to examine the performance four different models. I tried to keep the model types as diverse as possible:\n",
    "\n",
    "- k-nearest neighbors (non-parametric)\n",
    "- logistic regression (linear)\n",
    "- random forest (tree + bagging)\n",
    "- gradient boosting (tree + boosting)\n",
    "\n",
    "Further hyperparameter tuning was performed for the most promising model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processed/train.csv')\n",
    "test = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns=['claim_number', 'fraud']), train['fraud']\n",
    "X_test = test.drop(columns=['claim_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.columns[X_train.dtypes == object].tolist()\n",
    "column_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"k-nearest-neighbors\": KNeighborsClassifier(),\n",
    "    \"logistic-regression\": LogisticRegression(),\n",
    "    \"random-forest\": RandomForestClassifier(),\n",
    "    \"gradient-boost\": GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>std_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-nearest-neighbors</td>\n",
       "      <td>0.560769</td>\n",
       "      <td>0.013607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.704148</td>\n",
       "      <td>0.012404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random-forest</td>\n",
       "      <td>0.686333</td>\n",
       "      <td>0.005503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gradient-boost</td>\n",
       "      <td>0.717776</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  mean_cv_score  std_cv_score\n",
       "0  k-nearest-neighbors       0.560769      0.013607\n",
       "1  logistic-regression       0.704148      0.012404\n",
       "2        random-forest       0.686333      0.005503\n",
       "3       gradient-boost       0.717776      0.011023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9394)\n",
    "\n",
    "records = []\n",
    "for name, model in model_dict.items():\n",
    "    if name in ('k-nearest-neighbors', 'logistic-regression'):\n",
    "        steps = [column_transformer, standard_scaler, model]\n",
    "    else:\n",
    "        steps = [column_transformer, model]\n",
    "    pipeline = make_pipeline(*steps)\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    std_cv_score = np.std(cv_scores)\n",
    "    records.append({'name': name, 'mean_cv_score': np.mean(cv_scores), 'std_cv_score': np.std(cv_scores)})\n",
    "pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost had the best performance. I tried to see if I could get an even better performance from it using some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the hyperparameters we can tune for `GradientBoostingClassifier`:\n",
    "\n",
    "- `learning_rate`\n",
    "- `n_estimators`\n",
    "- `subsample`\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `max_depth`\n",
    "- `max_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "pipeline = make_pipeline(column_transformer, GradientBoostingClassifier())\n",
    "distributions = {\n",
    "    'gradientboostingclassifier__learning_rate': scipy.stats.uniform(),\n",
    "    'gradientboostingclassifier__n_estimators': scipy.stats.randint(10, 100),\n",
    "    'gradientboostingclassifier__subsample': scipy.stats.uniform(),\n",
    "    'gradientboostingclassifier__min_samples_split': scipy.stats.uniform(),\n",
    "    'gradientboostingclassifier__min_samples_leaf': scipy.stats.randint(1, 10),\n",
    "    'gradientboostingclassifier__max_depth': scipy.stats.randint(1, 5),\n",
    "    'gradientboostingclassifier__max_features': scipy.stats.randint(1, 20),\n",
    "}\n",
    "\n",
    "hparam_tuner = RandomizedSearchCV(pipeline, distributions, n_iter=50, cv=5, scoring='roc_auc')\n",
    "hparam_tuner = hparam_tuner.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440257</td>\n",
       "      <td>71</td>\n",
       "      <td>0.849432</td>\n",
       "      <td>0.531828</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.721221</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.317285</td>\n",
       "      <td>53</td>\n",
       "      <td>0.495492</td>\n",
       "      <td>0.250455</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.664872</td>\n",
       "      <td>35</td>\n",
       "      <td>0.438214</td>\n",
       "      <td>0.403355</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.718460</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.293152</td>\n",
       "      <td>49</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.716600</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.305229</td>\n",
       "      <td>68</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.715922</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.322568</td>\n",
       "      <td>29</td>\n",
       "      <td>0.634442</td>\n",
       "      <td>0.629728</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.713760</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.337066</td>\n",
       "      <td>31</td>\n",
       "      <td>0.440643</td>\n",
       "      <td>0.157035</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.712440</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.627317</td>\n",
       "      <td>78</td>\n",
       "      <td>0.631792</td>\n",
       "      <td>0.398044</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.711341</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.565011</td>\n",
       "      <td>92</td>\n",
       "      <td>0.832837</td>\n",
       "      <td>0.263981</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708463</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.965698</td>\n",
       "      <td>93</td>\n",
       "      <td>0.769397</td>\n",
       "      <td>0.588017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.707308</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.265358</td>\n",
       "      <td>86</td>\n",
       "      <td>0.429813</td>\n",
       "      <td>0.352992</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706033</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.161069</td>\n",
       "      <td>95</td>\n",
       "      <td>0.204543</td>\n",
       "      <td>0.065462</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.705944</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.507204</td>\n",
       "      <td>59</td>\n",
       "      <td>0.69197</td>\n",
       "      <td>0.108542</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.703932</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.963004</td>\n",
       "      <td>42</td>\n",
       "      <td>0.305114</td>\n",
       "      <td>0.24817</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698150</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.295877</td>\n",
       "      <td>13</td>\n",
       "      <td>0.731073</td>\n",
       "      <td>0.352042</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693326</td>\n",
       "      <td>0.014647</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.005545</td>\n",
       "      <td>93</td>\n",
       "      <td>0.461909</td>\n",
       "      <td>0.077223</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.691677</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1601</td>\n",
       "      <td>26</td>\n",
       "      <td>0.309884</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.691217</td>\n",
       "      <td>0.020338</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.573774</td>\n",
       "      <td>15</td>\n",
       "      <td>0.189567</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.684425</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.04734</td>\n",
       "      <td>29</td>\n",
       "      <td>0.300517</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.678894</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.281235</td>\n",
       "      <td>10</td>\n",
       "      <td>0.597433</td>\n",
       "      <td>0.474595</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.872879</td>\n",
       "      <td>93</td>\n",
       "      <td>0.637751</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.664020</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.683989</td>\n",
       "      <td>47</td>\n",
       "      <td>0.313669</td>\n",
       "      <td>0.463653</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.592392</td>\n",
       "      <td>27</td>\n",
       "      <td>0.702104</td>\n",
       "      <td>0.744781</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.698564</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.562218</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.40939</td>\n",
       "      <td>61</td>\n",
       "      <td>0.626309</td>\n",
       "      <td>0.980582</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.897305</td>\n",
       "      <td>88</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.683615</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.266906</td>\n",
       "      <td>71</td>\n",
       "      <td>0.575135</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.811644</td>\n",
       "      <td>94</td>\n",
       "      <td>0.462685</td>\n",
       "      <td>0.841278</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.60295</td>\n",
       "      <td>48</td>\n",
       "      <td>0.172343</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>93</td>\n",
       "      <td>0.491119</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.765096</td>\n",
       "      <td>92</td>\n",
       "      <td>0.814844</td>\n",
       "      <td>0.881347</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780028</td>\n",
       "      <td>83</td>\n",
       "      <td>0.401018</td>\n",
       "      <td>0.480932</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.724455</td>\n",
       "      <td>37</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>0.654721</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.987995</td>\n",
       "      <td>44</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>0.433701</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154082</td>\n",
       "      <td>36</td>\n",
       "      <td>0.115618</td>\n",
       "      <td>0.501837</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.232836</td>\n",
       "      <td>61</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>0.797728</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.342764</td>\n",
       "      <td>21</td>\n",
       "      <td>0.267804</td>\n",
       "      <td>0.681301</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.456748</td>\n",
       "      <td>16</td>\n",
       "      <td>0.175373</td>\n",
       "      <td>0.270515</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.314966</td>\n",
       "      <td>27</td>\n",
       "      <td>0.520877</td>\n",
       "      <td>0.572457</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.554383</td>\n",
       "      <td>70</td>\n",
       "      <td>0.392944</td>\n",
       "      <td>0.84167</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.231301</td>\n",
       "      <td>98</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.638023</td>\n",
       "      <td>50</td>\n",
       "      <td>0.762768</td>\n",
       "      <td>0.875051</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.367865</td>\n",
       "      <td>75</td>\n",
       "      <td>0.130895</td>\n",
       "      <td>0.552044</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.321981</td>\n",
       "      <td>54</td>\n",
       "      <td>0.316788</td>\n",
       "      <td>0.559487</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.354265</td>\n",
       "      <td>97</td>\n",
       "      <td>0.521533</td>\n",
       "      <td>0.55237</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002688</td>\n",
       "      <td>56</td>\n",
       "      <td>0.282321</td>\n",
       "      <td>0.292489</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.450636</td>\n",
       "      <td>66</td>\n",
       "      <td>0.241828</td>\n",
       "      <td>0.296861</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.780998</td>\n",
       "      <td>95</td>\n",
       "      <td>0.111392</td>\n",
       "      <td>0.992614</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.683843</td>\n",
       "      <td>71</td>\n",
       "      <td>0.485397</td>\n",
       "      <td>0.909872</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.056083</td>\n",
       "      <td>13</td>\n",
       "      <td>0.165938</td>\n",
       "      <td>0.255843</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate n_estimators subsample min_samples_split min_samples_leaf  \\\n",
       "3       0.440257           71  0.849432          0.531828                3   \n",
       "7       0.317285           53  0.495492          0.250455                7   \n",
       "26      0.664872           35  0.438214          0.403355                9   \n",
       "47      0.293152           49  0.792208          0.651643                9   \n",
       "36      0.305229           68  0.806604          0.411569                6   \n",
       "45      0.322568           29  0.634442          0.629728                2   \n",
       "28      0.337066           31  0.440643          0.157035                5   \n",
       "2       0.627317           78  0.631792          0.398044                5   \n",
       "32      0.565011           92  0.832837          0.263981                8   \n",
       "34      0.965698           93  0.769397          0.588017                1   \n",
       "48      0.265358           86  0.429813          0.352992                1   \n",
       "22      0.161069           95  0.204543          0.065462                4   \n",
       "13      0.507204           59   0.69197          0.108542                9   \n",
       "42      0.963004           42  0.305114           0.24817                1   \n",
       "21      0.295877           13  0.731073          0.352042                9   \n",
       "41      0.005545           93  0.461909          0.077223                6   \n",
       "12        0.1601           26  0.309884          0.016129                2   \n",
       "35      0.573774           15  0.189567          0.049097                4   \n",
       "39       0.04734           29  0.300517           0.23825                2   \n",
       "46      0.281235           10  0.597433          0.474595                2   \n",
       "49      0.872879           93  0.637751          0.069735                3   \n",
       "38      0.683989           47  0.313669          0.463653                1   \n",
       "33      0.592392           27  0.702104          0.744781                2   \n",
       "30      0.698564           90    0.2014          0.562218                8   \n",
       "40       0.40939           61  0.626309          0.980582                2   \n",
       "43      0.897305           88  0.025242          0.683615                1   \n",
       "44      0.266906           71  0.575135          0.993033                1   \n",
       "31      0.811644           94  0.462685          0.841278                1   \n",
       "37       0.60295           48  0.172343          0.989035                4   \n",
       "0       0.696469           93  0.491119          0.551315                3   \n",
       "27      0.765096           92  0.814844          0.881347                4   \n",
       "1       0.780028           83  0.401018          0.480932                2   \n",
       "4       0.724455           37  0.234513          0.654721                2   \n",
       "5       0.987995           44  0.173907          0.433701                6   \n",
       "6       0.154082           36  0.115618          0.501837                5   \n",
       "8       0.232836           61  0.545068          0.797728                3   \n",
       "9       0.342764           21  0.267804          0.681301                7   \n",
       "10      0.456748           16  0.175373          0.270515                4   \n",
       "11      0.314966           27  0.520877          0.572457                7   \n",
       "14      0.554383           70  0.392944           0.84167                8   \n",
       "15      0.231301           98  0.004135          0.704959                4   \n",
       "16      0.638023           50  0.762768          0.875051                8   \n",
       "17      0.367865           75  0.130895          0.552044                9   \n",
       "18      0.321981           54  0.316788          0.559487                2   \n",
       "19      0.354265           97  0.521533           0.55237                4   \n",
       "20      0.002688           56  0.282321          0.292489                4   \n",
       "23      0.450636           66  0.241828          0.296861                5   \n",
       "25      0.780998           95  0.111392          0.992614                6   \n",
       "29      0.683843           71  0.485397          0.909872                4   \n",
       "24      0.056083           13  0.165938          0.255843                3   \n",
       "\n",
       "   max_depth max_features  mean_test_score  std_test_score  rank_test_score  \n",
       "3          1            8         0.721221        0.011237                1  \n",
       "7          1            8         0.718594        0.010972                2  \n",
       "26         2           11         0.718460        0.012740                3  \n",
       "47         1            9         0.716600        0.009147                4  \n",
       "36         2            2         0.715922        0.010207                5  \n",
       "45         2           17         0.713760        0.013558                6  \n",
       "28         1           10         0.712440        0.012263                7  \n",
       "2          2           15         0.711341        0.012896                8  \n",
       "32         1            1         0.708463        0.012820                9  \n",
       "34         2           11         0.707308        0.011313               10  \n",
       "48         3            1         0.706033        0.008350               11  \n",
       "22         4           15         0.705944        0.008544               12  \n",
       "13         3           16         0.703932        0.014126               13  \n",
       "42         3            3         0.698150        0.009768               14  \n",
       "21         3            4         0.693326        0.014647               15  \n",
       "41         3           14         0.691677        0.013782               16  \n",
       "12         1            4         0.691217        0.020338               17  \n",
       "35         2           15         0.684425        0.015128               18  \n",
       "39         2           10         0.678894        0.008482               19  \n",
       "46         1            6         0.669922        0.012678               20  \n",
       "49         4            6         0.664020        0.013218               21  \n",
       "38         3           18         0.500000        0.000000               22  \n",
       "33         3            7         0.500000        0.000000               22  \n",
       "30         3           15         0.500000        0.000000               22  \n",
       "40         4           14         0.500000        0.000000               22  \n",
       "43         4           16         0.500000        0.000000               22  \n",
       "44         1            7         0.500000        0.000000               22  \n",
       "31         4           18         0.500000        0.000000               22  \n",
       "37         3           17         0.500000        0.000000               22  \n",
       "0          3            3         0.500000        0.000000               22  \n",
       "27         4            7         0.500000        0.000000               22  \n",
       "1          2            1         0.500000        0.000000               22  \n",
       "4          1            7         0.500000        0.000000               22  \n",
       "5          4           11         0.500000        0.000000               22  \n",
       "6          3            5         0.500000        0.000000               22  \n",
       "8          3           18         0.500000        0.000000               22  \n",
       "9          1           18         0.500000        0.000000               22  \n",
       "10         3            4         0.500000        0.000000               22  \n",
       "11         4            7         0.500000        0.000000               22  \n",
       "14         4            5         0.500000        0.000000               22  \n",
       "15         4           13         0.500000        0.000000               22  \n",
       "16         4            5         0.500000        0.000000               22  \n",
       "17         3           14         0.500000        0.000000               22  \n",
       "18         3           13         0.500000        0.000000               22  \n",
       "19         3            2         0.500000        0.000000               22  \n",
       "20         3           19         0.500000        0.000000               22  \n",
       "23         4            5         0.500000        0.000000               22  \n",
       "25         4            3         0.500000        0.000000               22  \n",
       "29         1            4         0.500000        0.000000               22  \n",
       "24         2            6         0.500000        0.000000               22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    hparam_tuner.cv_results_,\n",
    "    columns=[\n",
    "        'param_gradientboostingclassifier__learning_rate',\n",
    "        'param_gradientboostingclassifier__n_estimators',\n",
    "        'param_gradientboostingclassifier__subsample',\n",
    "        'param_gradientboostingclassifier__min_samples_split',\n",
    "        'param_gradientboostingclassifier__min_samples_leaf',\n",
    "        'param_gradientboostingclassifier__max_depth',\n",
    "        'param_gradientboostingclassifier__max_features',\n",
    "        'mean_test_score',\n",
    "        'std_test_score',\n",
    "        'rank_test_score',\n",
    "    ],\n",
    ").rename(\n",
    "    columns={\n",
    "        'param_gradientboostingclassifier__learning_rate': 'learning_rate',\n",
    "        'param_gradientboostingclassifier__n_estimators': 'n_estimators',\n",
    "        'param_gradientboostingclassifier__subsample': 'subsample',\n",
    "        'param_gradientboostingclassifier__min_samples_split': 'min_samples_split',\n",
    "        'param_gradientboostingclassifier__min_samples_leaf': 'min_samples_leaf',\n",
    "        'param_gradientboostingclassifier__max_depth': 'max_depth',\n",
    "        'param_gradientboostingclassifier__max_features': 'max_features',\n",
    "    }\n",
    ").sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = hparam_tuner.best_estimator_\n",
    "probs = best_model.predict_proba(X_test)\n",
    "df = pd.DataFrame({'claim_number': test['claim_number'], 'fraud': probs[:, 1]})\n",
    "df.to_csv(\"../submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/best_model.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>past_num_of_claims</td>\n",
       "      <td>0.147125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>annual_income</td>\n",
       "      <td>0.139702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accident_site_Parking Lot</td>\n",
       "      <td>0.127698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high_education_ind</td>\n",
       "      <td>0.107904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>witness_present_ind</td>\n",
       "      <td>0.085897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>claim_est_payout</td>\n",
       "      <td>0.081348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>0.062094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>safty_rating</td>\n",
       "      <td>0.055140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>address_change_ind</td>\n",
       "      <td>0.047272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>age_of_vehicle</td>\n",
       "      <td>0.037471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>liab_prct</td>\n",
       "      <td>0.021260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_F</td>\n",
       "      <td>0.020764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accident_site_Highway</td>\n",
       "      <td>0.017655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.016191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>age_of_driver</td>\n",
       "      <td>0.012957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>vehicle_price</td>\n",
       "      <td>0.008450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>living_status_Own</td>\n",
       "      <td>0.005471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vehicle_category_Large</td>\n",
       "      <td>0.002524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.001846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vehicle_category_Medium</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vehicle_weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vehicle_color_white</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vehicle_color_silver</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vehicle_color_red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vehicle_color_other</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vehicle_color_gray</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vehicle_color_blue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vehicle_color_black</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vehicle_category_Compact</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>policy_report_filed_ind</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>living_status_Rent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender_M</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>channel_Phone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>channel_Online</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>channel_Broker</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accident_site_Local</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_name  importance\n",
       "26         past_num_of_claims    0.147125\n",
       "23              annual_income    0.139702\n",
       "6   accident_site_Parking Lot    0.127698\n",
       "24         high_education_ind    0.107904\n",
       "27        witness_present_ind    0.085897\n",
       "30           claim_est_payout    0.081348\n",
       "21             marital_status    0.062094\n",
       "22               safty_rating    0.055140\n",
       "25         address_change_ind    0.047272\n",
       "31             age_of_vehicle    0.037471\n",
       "28                  liab_prct    0.021260\n",
       "0                    gender_F    0.020764\n",
       "4       accident_site_Highway    0.017655\n",
       "35                  longitude    0.016191\n",
       "20              age_of_driver    0.012957\n",
       "32              vehicle_price    0.008450\n",
       "2           living_status_Own    0.005471\n",
       "11     vehicle_category_Large    0.002524\n",
       "34                   latitude    0.001846\n",
       "12    vehicle_category_Medium    0.001232\n",
       "33             vehicle_weight    0.000000\n",
       "19        vehicle_color_white    0.000000\n",
       "18       vehicle_color_silver    0.000000\n",
       "17          vehicle_color_red    0.000000\n",
       "16        vehicle_color_other    0.000000\n",
       "15         vehicle_color_gray    0.000000\n",
       "14         vehicle_color_blue    0.000000\n",
       "13        vehicle_color_black    0.000000\n",
       "10   vehicle_category_Compact    0.000000\n",
       "29    policy_report_filed_ind    0.000000\n",
       "3          living_status_Rent    0.000000\n",
       "1                    gender_M    0.000000\n",
       "9               channel_Phone    0.000000\n",
       "8              channel_Online    0.000000\n",
       "7              channel_Broker    0.000000\n",
       "5         accident_site_Local    0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_dummies(df, categorical_features):\n",
    "    dummies = pd.get_dummies(df[categorical_features])\n",
    "    res = pd.concat([dummies, df], axis=1)\n",
    "    res = res.drop(categorical_features, axis=1)\n",
    "    return res.columns\n",
    "\n",
    "feature_names = add_dummies(X_train, categorical_features)\n",
    "importances = best_model.steps[-1][1].feature_importances_\n",
    "pd.DataFrame(\n",
    "    {'feature_name': feature_names, 'importance': importances}\n",
    ").sort_values(by=['importance', 'feature_name'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03e93f2959c516196957ae17ec0aa5d1e9fc5dd82cbe13968d4cfc2a60558992"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
